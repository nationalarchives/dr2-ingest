# 20. Aggregation for TDR Preingest

**Date:** 2024-08-14

## Context

The first source to ingest into DR2 was parsed court documents, transferred via TDR and parsed by TRE. To transform the BagIt delivered to us by TRE to a DR2 BagIt-like package, we created a bespoke preingest route for this source, responsible for both the transform and mapping of source system-specific fields into our data model. For example, creating a folder for the court case and adding the `Cite` reference to our ingested entities. The upstream workflow for this type of record enforces a 1-1 relationship between a transfer consignment and a record, we're now ready to create a new preingest route for standard TDR transfers.

Standard TDR transfers contain multiple files within a consignment; the count and size of the files is at the discretion of the transferring body. While the Preservation System ingest process is most efficient when ingesting batches, as opposed to individual files, the optimal size of these batches is unlikely to match the size of batches created in systems upstream of DR2. We want to design our preingest process for TDR to be most efficient for the Preservation System, creating batches of a size we can configure, based upon limitations of the product and our operational priorities - we may decide to change the batch size depending on source system to horizontally scale our ingest capability.

## Decision

We will implement an aggregation process as part of our TDR Preingest workflow; we will request TDR notify us of new records for ingest, with a message per record to allow us to aggregate records into ingest batches of a configurable size. This is opposed to a message per transfer consignment, which could contain multiple records. Our aggregation process will use the same AWS services as our ingest process - SQS, Lambda, Step Functions, and DynamoDB.

### Aggregation Design

![TDR Aggregation Diagram](/docs/images/adr/0020/tdr-aggregation-diagram.png)

We will extend our usage of the existing dr2-ingest-lock table (created for [`0016-generic-ingest-idempotency.md`](./0016-generic-ingest-idempotency.md)) to act as a lock table within our aggregation. We will add a `groupId` attribute and GSI on this and a `message` attribute to store the JSON string of the message received from TDR. The `groupId` will be a unique identifier shared by all messages aggregated into a single group.

Messages will be received into an SQS queue with an [Event Source Mapping](https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html) configured to a Lambda function. The Lambda will attempt to write each message to the lock table. The Event Source Mapping will be set with a `MaximumBatchingWindowInSeconds` of 300 seconds and `BatchSize` of 10,000; the Lambda will only be invoked when the SQS poller has: 10,000 messages ready, 300 seconds have elapsed since the first message was received by the poller, or the Lambda payload is 6MB.

To enable processing of batches larger than 10,000 records, we will cache the current `groupId` within the Lambda container and delay processing of the group for a configurable period whilst other messages can still be added; the result of this will be that multiple invocations within the same Lambda container can add messages to a single aggregation group. Once this period has elapsed, we will collect the messages from the lock table by querying with the `groupId` and use these to build a DR2 BagIt-like ingest package. The items in the lock table will be deleted as normal when the ingest process is complete. As we're using a GSI within this solution, we will add a step to the Generic Ingest workflow to check all items have been removed from the lock table. If any items remain, we will run repeat the package building process; creating a new DR2 BagIt-like package for the remaining messages. To aid terminology, we will **aggregate into groups and ingest in batches**, where a batch is a combination of `groupId` and `retryCount`.

### Alternatives considered

| Description                                                          | Pros                                                                                                                                           | Cons                                                                                                                                                                                                                                                                                                                                                                                              |
| -------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Ingest in transfer consignment batches.                              | - The preingest would be a simple transform from BagIt to DR2 BagIt-like.<br>- Reporting of ingest status would easy for humans to understand. | - Size of ingest batches is user defined and unoptimized for the Preservation System.<br>- TDR BagIt packages are `.tar.gz` compressed, we'd need to build a process to unpack as part of the transformation. As consignments get larger we may struggle to do this using Serverless services.<br>- Large transfers, or transfers from systems other than TDR, will require a different solution. |
| Ingest single records per workflow execution.                        | - Easy to implement.                                                                                                                           | - Extremely inefficient for Preservation System.<br>- Unable to scale easily.<br>- May reach AWS quota limits for the number concurrent workflows.                                                                                                                                                                                                                                                |
| Store incoming events and trigger ingest using scheduled/cron tasks. | - DR2 can control ingest batch size.                                                                                                           | - May struggle to scale during high load; messages could be held without processing for extended periods.<br>- Requires new database technology to query and update many rows in a single action.<br>- Anti-pattern to event-based architecture as events are not triggering consumers.                                                                                                           |
| Group using SQS batching only.                                       | - Can support batches of up to 10,000 records natively in AWS.                                                                                 | - SQS's at-least-once delivery will result in the same asset within multiple concurrent ingests.<br>- Batches with >10,000 records may be required for efficiency.                                                                                                                                                                                                                                |

## Consequences

- Added complexity. Implementing aggregation in this way will increase the complexity of the system.
- Difficulty to rollback. As ingest batches will be large, it will be difficult to triage and remove a single asset from a batch if problems occur.
- Increased cost. We're using Serverless components for this workflow, in most cases this will save money but during large ingests this may be detrimental.
- Changes to existing ingest workflow. Implementing this will necessitate changes to the Generic Ingest workflow and Court Document Preingest workflow.
- Increased latency. We will be adding up to 5 minutes of latency for the SQS poller batching and another, configurable, delay step in our process before we can ingest an asset.
